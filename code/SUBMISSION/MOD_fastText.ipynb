{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fasttext\n",
    "import fasttext\n",
    "\n",
    "# submission\n",
    "from create_csv_submission import create_csv_submission\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# other\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read tweet full collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change path to read the full tweet collection\n",
    "os.chdir(r'/home/ilaria/Scrivania/data_ML/twitter_datasets_epfl/full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filenames\n",
    "fname_neg = 'train_neg_full_processed.txt'\n",
    "fname_pos = 'train_pos_full_processed.txt'\n",
    "fname_test = 'test_data_no_id_processed.txt'\n",
    "\n",
    "# read \n",
    "with open(fname_neg, 'r', encoding=\"utf-8-sig\") as f:\n",
    "    text_neg_tr = f.readlines()\n",
    "with open(fname_pos, 'r', encoding=\"utf-8-sig\") as f:\n",
    "    text_pos_tr = f.readlines()\n",
    "with open(fname_test, 'r', encoding=\"utf-8-sig\") as f:\n",
    "    text_test = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format negative tweets\n",
    "string_to_add = '__label__-1 '\n",
    "with open(fname_neg, 'r', encoding=\"utf-8-sig\") as f:\n",
    "    lines = [''.join([string_to_add, x.strip(),'\\n']) for x in f]   \n",
    "with open('mytrain_neg.txt', 'w') as f:\n",
    "    f.writelines(lines) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format positive tweets\n",
    "string_to_add = '__label__1 '\n",
    "with open(fname_pos, 'r', encoding=\"utf-8-sig\") as f:\n",
    "    lines = [''.join([string_to_add, x.strip(),'\\n']) for x in f]   \n",
    "with open('mytrain_pos.txt', 'w') as f:\n",
    "    f.writelines(lines) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read formated data\n",
    "with open('mytrain_pos.txt', 'r', encoding=\"utf-8-sig\") as f1:\n",
    "    lines1 = f1.readlines()\n",
    "with open('mytrain_neg.txt', 'r', encoding =\"utf-8-sig\") as f2:\n",
    "    lines2 = f2.readlines()    \n",
    "with open('train_all.txt', 'w') as f:\n",
    "    f.writelines(lines1)\n",
    "    f.writelines(lines2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build a cbow model\n",
    "model = fasttext.cbow('all_full_processed.txt', 'model', ws = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "classifier = fasttext.supervised('train_all.txt', 'model', label_prefix='__label__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read test data\n",
    "filename_test = 'test_data_no_id_processed.txt'\n",
    "with open(filename_test, 'r', encoding= 'utf-8-sig') as f:\n",
    "    texts = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "labels = classifier.predict(texts)\n",
    "\n",
    "# format predictions\n",
    "y_pred = np.array([int(labels[x][0]) for x in range(len(labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapt path\n",
    "os.chdir(r'D:/Documents/etudes/epfl/MA1/cours/MachineLearning/Project2/data/submissions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output file name\n",
    "i = datetime.datetime.now()\n",
    "name = \"sub_\" + time.strftime(\"%d_%m_%Y\") +  \"_%sh_%smin\" % (i.hour, i.minute)\n",
    "ids_test = range(1, test_arrays.shape[0]+1)\n",
    "\n",
    "# write submission file\n",
    "create_csv_submission(ids_test, y_pred, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
